写这篇文章，想和大家从头到脚说说任务调度，希望大家读完之后，能够理解实现一个任务调度系统的核心逻辑。

![img](https://oscimg.oschina.net/oscnet/up-75473a847f1773d2bd20f4d3e0a6f7d3264.png)

# 1 Quartz

Quartz是一款Java开源任务调度框架，也是很多Java工程师接触任务调度的起点。

下图显示了任务调度的整体流程： ![img](https://oscimg.oschina.net/oscnet/up-e23c974db26a1fbf8ffd14aad0812cd7a8f.png)

Quartz的核心是三个组件。

- 任务：Job 用于表示被调度的任务；
- 触发器：Trigger 定义调度时间的元素，即按照什么时间规则去执行任务。一个Job可以被多个Trigger关联，但是一个Trigger 只能关联一个Job；
- 调度器 ：工厂类创建Scheduler，根据触发器定义的时间规则调度任务。

![img](https://oscimg.oschina.net/oscnet/up-ec232e213db3eb917dee430d2a9aac59be2.png)

上图代码中Quartz 的JobStore是 **RAMJobStore**，Trigger 和 Job 存储在内存中。

执行任务调度的核心类是 **QuartzSchedulerThread** 。

![img](https://oscimg.oschina.net/oscnet/up-d12a2412224d1b3cc51b6ba44375ff83842.png)

1. 调度线程从JobStore中获取需要执行的的触发器列表，并修改触发器的状态；
2. <font color="red">**Fire**</font>触发器，修改触发器信息(下次执行触发器的时间，以及触发器状态），并存储起来。
3. 最后创建具体的执行任务对象，通过worker线程池执行任务。

接下来再聊聊 Quartz 的集群部署方案。

Quartz的集群部署方案，需要针对不同的数据库类型(MySQL , ORACLE) 在数据库实例上创建Quartz表，JobStore是: **JobStoreSupport** 。

这种方案是分布式的，没有负责集中管理的节点，而是利用数据库行级锁的方式来实现集群环境下的并发控制。

scheduler实例在集群模式下首先获取{0}LOCKS表中的行锁，Mysql 获取行锁的语句：

![img](https://oscimg.oschina.net/oscnet/up-ccc5459ed1bc6357b2bbe6d3c219898e0e0.png)

{0}会替换为配置文件默认配置的`QRTZ_`。sched_name为应用集群的实例名，lock_name就是行级锁名。Quartz主要有两个行级锁触发器访问锁 (**TRIGGER_ACCESS**) 和 状态访问锁（**STATE_ACCESS**）。

![img](https://oscimg.oschina.net/oscnet/up-c4938fc53033e808b885c8f0556ca5a202e.png)

这个架构解决了任务的分布式调度问题，同一个任务只能有一个节点运行，其他节点将不执行任务，当碰到大量短任务时，各个节点频繁的竞争数据库锁，节点越多性能就会越差。

# 2 分布式锁模式

Quartz的集群模式可以水平扩展，也可以分布式调度，但需要业务方在数据库中添加对应的表，有一定的强侵入性。

有不少研发同学为了避免这种侵入性，也探索出**分布式锁模式**。

业务场景：电商项目，用户下单后一段时间没有付款，系统就会在超时后关闭该订单。

通常我们会做一个定时任务每两分钟来检查前半小时的订单，将没有付款的订单列表查询出来，然后对订单中的商品进行库存的恢复，然后将该订单设置为无效。

我们使用Spring Schedule的方式做一个定时任务。

```java
@Scheduled(cron = "0 */2 * * * ? ")
public void doTask() {
   log.info("定时任务启动");
   //执行关闭订单的操作
   orderService.closeExpireUnpayOrders();
   log.info("定时任务结束");
 }
```

在单服务器运行正常，考虑到高可用，业务量激增，架构会演进成集群模式，在**同一时刻**有多个服务执行一个定时任务，有可能会导致业务紊乱。

解决方案是在任务执行的时候，使用Redis 分布式锁来解决这类问题。

```java
@Scheduled(cron = "0 */2 * * * ? ")
public void doTask() {
    log.info("定时任务启动");
    String lockName = "closeExpireUnpayOrdersLock";
    RedisLock redisLock = redisClient.getLock(lockName);
    //尝试加锁，最多等待3秒，上锁以后5分钟自动解锁
    boolean locked = redisLock.tryLock(3, 300, TimeUnit.SECONDS);
    if(!locked){
        log.info("没有获得分布式锁:{}" , lockName);
        return;
    }
    try{
       //执行关闭订单的操作
       orderService.closeExpireUnpayOrders();
    } finally {
       redisLock.unlock();
    }
    log.info("定时任务结束");
}
```

![img](https://oscimg.oschina.net/oscnet/up-f26cdc989f3f8e56063c0f3d4c22d32881d.png)

Redis的读写性能极好，分布式锁也比Quartz数据库行级锁更轻量级。当然Redis锁也可以替换成Zookeeper锁，也是同样的机制。

在小型项目中，使用：定时任务框架（Quartz/Spring Schedule）和 分布式锁（redis/zookeeper）有不错的效果。

但是呢？我们可以发现这种组合有两个问题：

1. 定时任务在分布式场景下有空跑的情况，而且任务也无法做到分片；
2. 要想手工触发任务，必须添加额外的代码才能完成。

# 3 ElasticJob-Lite 框架

ElasticJob-Lite 定位为轻量级无中心化解决方案，使用 jar 的形式提供分布式任务的协调服务。 ![官网架构图](https://oscimg.oschina.net/oscnet/up-eeb73adcfa9ba8078b4fe6898b5567734db.png)

应用内部定义任务类，实现SimpleJob接口，编写自己任务的实际业务流程即可。

```
public class MyElasticJob implements SimpleJob {
    @Override
    public void execute(ShardingContext context) {
        switch (context.getShardingItem()) {
            case 0:
                // do something by sharding item 0
                break;
            case 1:
                // do something by sharding item 1
                break;
            case 2:
                // do something by sharding item 2
                break;
            // case n: ...
        }
    }
}
```

举例：应用A有五个任务需要执行，分别是A，B，C，D，E。任务E需要分成四个子任务，应用部署在两台机器上。

![img](https://oscimg.oschina.net/oscnet/up-5e99a1fc0b66b06f9694945eb97fb90a0e7.png)

应用A在启动后， 5个任务通过 Zookeeper 协调后被分配到两台机器上，通过Quartz Scheduler 分开执行不同的任务。

ElasticJob 从本质上来讲 ，底层任务调度还是通过 Quartz ，相比Redis分布式锁 或者 Quartz 分布式部署 ，它的优势在于可以依赖 Zookeeper 这个大杀器 ，将任务通过负载均衡算法分配给应用内的 Quartz Scheduler容器。

从使用者的角度来讲，是非常简单易用的。但从架构来看，调度器和执行器依然在同一个应用方JVM内，而且容器在启动后，依然需要做负载均衡。应用假如频繁的重启，不断的去选主，对分片做负载均衡，这些都是相对比较**重**的操作。

另外，ElasticJob 的控制台是比较粗糙的，通过读取注册中心数据展现作业状态，更新注册中心数据修改全局任务配置。

# 4 中心化流派

中心化的原理是：把调度和任务执行，隔离成两个部分：调度中心和执行器。调度中心模块只需要负责任务调度属性，触发调度命令。执行器接收调度命令，去执行具体的业务逻辑，而且两者都可以进行分布式扩容。

## 4.1 MQ模式

先谈谈我在艺龙促销团队接触的第一种中心化架构。

![img](https://oscimg.oschina.net/oscnet/up-9981634748170dc9fd7b3f865bb75867b5f.png)

调度中心依赖Quartz集群模式，当任务调度时候，发送消息到RabbitMQ 。业务应用收到任务消息后，消费任务信息。

这种模型充分利用了MQ解耦的特性，调度中心发送任务，应用方作为执行器的角色，接收任务并执行。

但这种设计强依赖消息队列，可扩展性和功能，系统负载都和消息队列有极大的关联。这种架构设计需要架构师对消息队列非常熟悉。

## 4.2 XXL-JOB

> XXL-JOB 是一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。

![xxl-job 2.3.0架构图](https://oscimg.oschina.net/oscnet/up-893a211c6a5d868f59014ff84f2a9f81087.png)

我们重点剖析下架构图 ：

**▍ 网络通讯 server-worker 模型**

![img](https://oscimg.oschina.net/oscnet/up-9b6663f0df0220f42ff61fcd5d1ff5c88a9.png)

调度中心和执行器 两个模块之间通讯是 server-worker 模式。调度中心本身就是一个SpringBoot 工程，启动会监听8080端口。

执行器启动后，会启动内置服务（ EmbedServer ）监听9994端口。这样双方都可以给对方发送命令。

那调度中心如何知道执行器的地址信息呢 ？上图中，执行器会定时发送注册命令 ，这样调度中心就可以获取在线的执行器列表。

通过执行器列表，就可以根据任务配置的路由策略选择节点执行任务。常见的路由策略有如下三种：

- 随机节点执行：选择集群中一个可用的执行节点执行调度任务。适用场景：离线订单结算。

![img](https://oscimg.oschina.net/oscnet/up-ce7a70cedbcb36153919e5593e4eb79b062.png)

- 广播执行：在集群中所有的执行节点分发调度任务并执行。适用场景：批量更新应用本地缓存。

  ![img](https://oscimg.oschina.net/oscnet/up-cf8b666184df9afdb487e1ba020c52af567.png)

- 分片执行：按照用户自定义分片逻辑进行拆分，分发到集群中不同节点并行执行，提升资源利用效率。适用场景：海量日志统计。

![img](https://oscimg.oschina.net/oscnet/up-9c3f4ed2e81d440e1e2f1038b27af975cb7.png)

**▍ 调度器**

调度器是任务调度系统里面非常核心的组件。XXL-JOB 的早期版本是依赖Quartz。

但在v2.1.0版本中完全去掉了Quartz的依赖，原来需要创建的 Quartz表也替换成了自研的表。

核心的调度类是：**JobTriggerPoolHelper** 。调用start方法后，会启动两个线程：scheduleThread 和 ringThread 。

首先 scheduleThread 会定时从数据库加载需要调度的任务，这里从本质上还是基于数据库行锁保证同时只有一个调度中心节点触发任务调度。

```java
Connection conn = XxlJobAdminConfig.getAdminConfig()
                  .getDataSource().getConnection();
connAutoCommit = conn.getAutoCommit();
conn.setAutoCommit(false);
preparedStatement = conn.prepareStatement(
"select * from xxl_job_lock where lock_name = 'schedule_lock' for update");
preparedStatement.execute();
# 触发任务调度 (伪代码)
for (XxlJobInfo jobInfo: scheduleList) {
  // 省略代码
}
# 事务提交
conn.commit();
```

调度线程会根据任务的「下次触发时间」，采取不同的动作：

![img](https://oscimg.oschina.net/oscnet/up-27f4924f874eb8ab9cafd7bcb4088e53396.png)

已过期的任务需要立刻执行的，直接放入线程池中触发执行 ，五秒内需要执行的任务放到 ringData 对象里。

ringThread 启动后，定时从 ringData 对象里获取需要执行的任务列表 ，放入到线程池中触发执行。

![img](https://oscimg.oschina.net/oscnet/up-89216be7263323487efbf19d8f8b77c2829.png) ![img](https://oscimg.oschina.net/oscnet/up-952db7d070dce21bf3cb2134838e03445c8.png)

# 5 自研在巨人的肩膀上

2018年，我有一段自研任务调度系统的经历。

背景是：兼容技术团队自研的RPC框架，技术团队不需要修改代码，RPC注解方法可以托管在任务调度系统中，直接当做一个任务来执行。

自研过程中，研读了XXL-JOB 源码，同时从阿里云分布式任务调度 SchedulerX 吸取了很多营养。

![SchedulerX 1.0 架构图](https://oscimg.oschina.net/oscnet/up-100857819cb86b3ec0750727cdd813fa1c6.png)

- Scheduler-console 是任务调度的控制台，用于创建、管理定时任务。负责数据的创建、修改和查询。在产品内部与 scheduler server 交互。
- Scheduler-server 是任务调度的服务端，是 Scheduler的核心组件。负责客户端任务的调度触发以及任务执行状态的监测。
- Scheduler-client 是任务调度的客户端。每个接入客户端的应用进程就是一个的 Worker。 Worker 负责与 scheduler-server 建立通信，让 scheduler-server发现客户端的机器。 并向scheduler-server注册当前应用所在的分组，这样 scheduler-server 才能向客户端定时触发任务。

我们模仿了SchedulerX的模块，架构设计如下图：

![img](https://oscimg.oschina.net/oscnet/up-11434037166443494604df623521104fb98.png)

我选择了 RocketMQ 源码的通讯模块 remoting 作为自研调度系统的通讯框架。基于如下两点：

1. 我对业界大名鼎鼎的 Dubbo不熟悉，而remoting我已经做了多个轮子，我相信自己可以搞定；
2. 在阅读 SchedulerX 1.0 client 源码中，发现 SchedulerX 的通讯框架和RocketMQ Remoting很多地方都很类似。它的源码里有现成的工程实现，完全就是一个宝藏。

我将 RocketMQ remoting 模块去掉名字服务代码，做了一定程度的定制。

在RocketMQ的remoting里，服务端采用 Processor 模式。

![img](https://oscimg.oschina.net/oscnet/up-afbd06b58d95a61d532600caa33ce05634f.png)

调度中心需要注册两个处理器：回调结果处理器CallBackProcessor和心跳处理器HeartBeatProcessor 。执行器需要注册触发任务处理器TriggerTaskProcessor 。

```java
public void registerProcessor(
             int requestCode,
             NettyRequestProcessor processor,
             ExecutorService executor);
```

处理器的接口：

```java
public interface NettyRequestProcessor {
 RemotingCommand processRequest(
                 ChannelHandlerContext ctx,
                 RemotingCommand request) throws Exception;
 boolean rejectRequest();
}
```

对于通讯框架来讲，我并不需要关注通讯细节，只需要实现处理器接口即可。

以触发任务处理器TriggerTaskProcessor举例：

![img](https://oscimg.oschina.net/oscnet/up-b77add858b775ed6545ad3cdf14f52ae9a4.png)

搞定网络通讯后，调度器如何设计 ？最终我还是选择了Quartz 集群模式。主要是基于以下几点原因：

1. 调度量不大的情况下 ，Quartz 集群模式足够稳定，而且可以兼容原来的XXL-JOB任务；
2. 使用时间轮的话，本身没有足够的实践经验，担心出问题。 另外，如何让任务通过不同的调度服务（schedule-server）触发， 需要有一个协调器。于是想到Zookeeper。但这样的话，又引入了新的组件。
3. 研发周期不能太长，想快点出成果。

自研版的调度服务花费一个半月上线了。系统运行非常稳定，研发团队接入也很顺畅。 调度量也不大 ，四个月总共接近4000万到5000万之间的调度量。

坦率的讲，自研版的瓶颈，我的脑海里经常能看到。 数据量大，我可以搞定分库分表，但 Quartz 集群基于行级锁的模式 ，注定上限不会太高。

为了解除心中的困惑，我写一个轮子DEMO看看可否work：

1. 去掉外置的注册中心，调度服务（schedule-server）管理会话；
2. 引入zookeeper，通过zk协调调度服务。但是HA机制很粗糙，相当于一个任务调度服务运行，另一个服务standby；
3. Quartz 替换成时间轮 （参考Dubbo里的时间轮源码）。

![img](https://oscimg.oschina.net/oscnet/up-d5c80f1f5f163880d66c38d981477d70536.png)

这个Demo版本在开发环境可以运行，但有很多细节需要优化，仅仅是个玩具，并没有机会运行到生产环境。

最近读阿里云的一篇文章《如何通过任务调度实现百万规则报警》，SchedulerX2.0 高可用架构见下图：

![img](https://oscimg.oschina.net/oscnet/up-40c6fda648bcd3516074d38c86fc9507514.jpg)

文章提到：

> 每个应用都会做三备份，通过 zk 抢锁，一主两备，如果某台 Server 挂了，会进行 failover，由其他 Server 接管调度任务。

这次自研任务调度系统从架构来讲，并不复杂，实现了XXL-JOB的核心功能，也兼容了技术团队的RPC框架，但并没有实现工作流以及mapreduce分片。

SchedulerX 在升级到2.0之后基于全新的Akka 架构，这种架构**号称**实现高性能工作流引擎，实现进程间通信，减少网络通讯代码。

在我调研的开源任务调度系统中，**PowerJob**也是基于Akka 架构，同时也实现了工作流和MapReduce执行模式。

我对**PowerJob**非常感兴趣，也会在学习实践后输出相关文章，敬请期待。

# 6 技术选型

首先我们将任务调度开源产品和商业产品 SchedulerX 放在一起，生成一张对照表：

![img](https://oscimg.oschina.net/oscnet/up-7d2f9c1945400c1e0ac77ca33f5b6ce3f56.png)

Quartz 和 ElasticJob从本质上还是属于框架的层面。

中心化产品从架构上来讲更加清晰，调度层面更灵活，可以支持更复杂的调度（mapreduce动态分片，工作流）。

XXL-JOB 从产品层面已经做到极简，开箱即用，调度模式可以满足大部分研发团队的需求。简单易用 + 能打，所以非常受大家欢迎。

其实每个技术团队的技术储备不尽相同，面对的场景也不一样，所以技术选型并不能一概而论。

不管是使用哪种技术，在编写任务业务代码时，还是需要注意两点：

- 幂等。当任务被重复执行的时候，或者分布式锁失效的时候，程序依然可以输出正确的结果；
- 任务不跑了，千万别惊慌。查看调度日志，JVM层面使用Jstack命令查看堆栈，网络通讯要添加超时时间 ，一般能解决大部分问题。

# 7 写到最后

2015年其实是非常有趣的一年。ElasticJob 和 XXL-JOB 这两种不同流派的任务调度项目都开源了。

在 XXL-JOB 源码里，至今还保留着许雪里老师在开源中国的一条动态截图：

> 刚写的任务调度框架 ，Web动态管理任务，实时生效，热乎的。没有意外的话，明天中午推送到git.osc上去。哈哈，下楼炒个面加个荷包蛋庆祝下。

看到这个截图，内心深处竟然会有一种共情，嘴角不自禁的上扬。

我又想起：2016年，ElasticJob的作者张亮老师开源了sharding-jdbc 。我在github上创建了一个私有项目，参考sharding-jdbc的源码，自己实现分库分表的功能。第一个类名叫：ShardingDataSource，时间定格在 2016/3/29。

我不知道如何定义“有创造力的软件工程师”，但我相信：一个有好奇心，努力学习，乐于分享，愿意去帮助别人的工程师，运气肯定不会太差。