## MySQL

### 基于唯一索引(`insert`)实现

**记录锁的乐观锁方案**。基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含**方法名**等字段，并在**方法名字段上创建唯一索引**，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。



#### 优缺点

**优点**

- 实现简单、易于理解

**缺点**

- 没有线程唤醒，获取失败就被丢掉了
- 没有超时保护，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁
- 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用
- 并发量大的时候请求量大，获取锁的间隔，如果较小会给系统和数据库造成压力
- 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错，没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作
- 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁，因为数据中数据已经存在了
- 这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁



#### 实现方案

```mysql
DROP TABLE IF EXISTS `method_lock`;
CREATE TABLE `method_lock` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `lock_key` varchar(64) NOT NULL DEFAULT '' COMMENT '锁的键值',
  `lock_timeout` datetime NOT NULL DEFAULT NOW() COMMENT '锁的超时时间',
  `remarks` varchar(255) NOT NULL COMMENT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_lock_key` (`lock_key`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT='锁定中的方法';
```

**① 获取锁**：想要执行某个方法，就使用这个方法名向表中插入数据

```mysql
INSERT INTO method_lock (lock_key, lock_timeout, remarks) VALUES ('methodName', '2021-07-19 18:20:00', '测试的methodName');
```

**② 释放锁**：释放锁的时候就删除记录

```mysql
DELETE FROM method_lock WHERE lock_key ='methodName';
```



#### 问题与解决

- 强依赖数据库可用性，是一个单点（部署双实例）
- 没有失效时间，一旦解锁失败，就会导致死锁（添加定时任务扫描表）
- 一旦插入失败就会直接报错，不会进入排队队列（使用while循环，成功后才返回）
- 是非重入锁，同一线程在没有释放锁之前无法再次获得该锁（添加字段记录机器和线程信息，查询时相同则直接分配）
- 非公平锁（建中间表记录等待锁的线程，根据创建时间排序后进行依次处理）
- 采用唯一索引冲突防重，在大并发情况下有可能会造成锁表现象（采用程序生产主键进行防重）



### 基于表字段版本号实现

**版本号对比更新的乐观锁方案**。一般是通过为数据库表添加一个 `version` 字段来实现读取出数据时，将此版本号一同读出。之后更新时，对此版本号加 `1`，在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。实际就是个`CAS`过程。



#### 优缺点

**缺点**

- 该方式使原本一次的update操作，必须变为2次操作：select版本号一次、update一次。增加了数据库操作的次数
- 如果业务场景中的一次业务流程中，多个资源都需要用保证数据一致性，那么如果全部使用基于数据库资源表的乐观锁，就要让每个资源都有一张资源表，这个在实际使用场景中肯定是无法满足的。而且这些都基于数据库操作，在高并发的要求下，对数据库连接的开销一定是无法忍受的
- 乐观锁机制往往基于系统中的数据存储逻辑，因此可能会造成脏数据被更新到数据库中



### 基于排他锁(`for update`)实现

**基于排它锁的悲观锁方案**。通过在select语句后增加`for update`来获取锁，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁，我们可以认为获得排它锁的线程即可获得分布式锁。释放锁通过`connection.commit();`操作，提交事务来实现。

#### 优缺点

**优点**

- 实现简单、易于理解

**缺点**

- 排他锁会占用连接，产生连接爆满的问题
- 如果表不大，可能并不会使用行锁
- 同样存在单点问题、并发量问题



#### 实现方案

**建表脚本**

```mysql
CREATE TABLE `methodLock` (
      `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
      `lock_key` varchar(64) NOT NULL DEFAULT '' COMMENT '锁的键值',
      `lock_timeout` datetime NOT NULL DEFAULT NOW() COMMENT '锁的超时时间',
      `remarks` varchar(255) NOT NULL COMMENT '备注信息',
      `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY ( `id` ),
    UNIQUE KEY `uidx_lock_key` ( `lock_key ` ) USING BTREE 
) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT = '锁定中的方法';
```

**加解锁操作**

```java
/**
 * 加锁
 */
public boolean lock() {
        // 开启事务
        connection.setAutoCommit(false);
        // 循环阻塞，等待获取锁
        while (true) {
            // 执行获取锁的sql
            String sql = "select * from methodLock where lock_key = xxx for update";
             // 创建prepareStatement对象，用于执行SQL
            ps = conn.prepareStatement(sql);
            // 获取查询结果集
            int result = ps.executeQuery();
            // 结果非空，加锁成功
            if (result != null) {
                return true;
            }
        }
    
        // 加锁失败
        return false;
}

/**
 * 解锁
 */
public void unlock() {
        // 提交事务，解锁
        connection.commit();
}
```



## Redis

### 锁的问题

#### 非原子操作

`加锁操作`和后面的`设置超时时间`是分开的，并`非原子操作`。解决方案：

**方案一：set命令**

```java
String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
if ("OK".equals(result)) {
    return true;
}
return false;
```

在redis中还有`set`命令是原子操作，加锁和设置超时时间，一个命令就能轻松搞定。其中：

- `lockKey`：锁的标识
- `requestId`：请求id
- `NX`：只在键不存在时，才对键进行设置操作
- `PX`：设置键的过期时间为 millisecond 毫秒
- `expireTime`：过期时



**方案二：LUA脚本**

```lua
if (redis.call('exists', KEYS[1]) == 0) then
    	redis.call('hset', KEYS[1], ARGV[2], 1); 
    	redis.call('pexpire', KEYS[1], ARGV[1]); 
		return nil; 
end
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1)
		redis.call('hincrby', KEYS[1], ARGV[2], 1); 
		redis.call('pexpire', KEYS[1], ARGV[1]); 
		return nil; 
end
return redis.call('pttl', KEYS[1]);
```



#### 忘了释放锁

加锁之后，每次都要达到了超时时间才释放锁，不会有点不合理。如果不及时释放锁，会有很多问题。合理流程如下：

![Redis释放锁流程](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/Redis释放锁流程.jpg)

释放锁的伪代码如下：

```java
try{
      String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
      if ("OK".equals(result)) {
          return true;
      }
      return false;
} finally {
   	 unlock(lockKey);
}  
```



#### 释放了别人的锁

自己只能释放自己加的锁，不允许释放别人加的锁。

**方案一：requestId方案**

伪代码如下：

```java
if (jedis.get(lockKey).equals(requestId)) {
    jedis.del(lockKey);
    return true;
}
return false;
```

**方案二：LUA脚本方案**

```lua
if redis.call('get', KEYS[1]) == ARGV[1] then 
	return redis.call('del', KEYS[1]) 
else 
 	return 0 
end
```



#### 大量失败请求

在秒杀场景下，会有什么问题？每1万个同时请求，有1个成功。再1万个同时请求，有1个成功。如此下去，直到库存不足。这就变成均匀分布的秒杀了，跟我们想象中的不一样（应该是谁先来谁得到）。

**解决方案：自旋锁**

在规定的时间，比如500毫秒内，自旋不断尝试加锁（说白了，就是在死循环中，不断尝试加锁），如果成功则直接返回。如果失败，则休眠50毫秒，再发起新一轮的尝试。如果到了超时时间，还未加锁成功，则直接返回失败。

```java
try {
  Long start = System.currentTimeMillis();
  while(true) {
           String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
           if ("OK".equals(result)) {
                 // 创建订单
                 createOrder();
                  return true;
           }

           long time = System.currentTimeMillis() - start;
            if (time>=timeout) {
                  return false;
            }
    
            try {
                Thread.sleep(50);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
  }
} finally{
    unlock(lockKey,requestId);
}  
return false;
```



#### 锁重入问题

假设需要获取一颗满足条件的菜单树。需要在接口中从根节点开始，递归遍历出所有满足条件的子节点，然后组装成一颗菜单树。在后台系统中运营同学可以动态添加、修改和删除菜单。为了保证在并发的情况下，每次都可能获取最新的数据，这里可以加redis分布式锁。在递归方法中递归遍历多次，每次都是加的同一把锁。递归第一层当然是可以加锁成功的，但递归第二层、第三层...第N层，不就会加锁失败了？

递归方法中加锁的伪代码（会出现异常）如下：

```java
private int expireTime = 1000;
public void fun(int level,String lockKey,String requestId){
  try{
     String result = jedis.set(lockKey, requestId, "NX", "PX", expireTime);
     if ("OK".equals(result)) {
        if(level<=10){
           this.fun(++level,lockKey,requestId);
        } else {
           return;
        }
     }
     return;
  } finally {
     unlock(lockKey,requestId);
  }
}
```

**基于Redisson实现可重入锁**

伪代码如下：

```java
private int expireTime = 1000;

public void run(String lockKey) {
  RLock lock = redisson.getLock(lockKey);
  this.fun(lock,1);
}

public void fun(RLock lock,int level){
  try{
      lock.lock(5, TimeUnit.SECONDS);
      if(level<=10){
         this.fun(lock,++level);
      } else {
         return;
      }
  } finally {
     lock.unlock();
  }
}
```



#### 锁竞争问题

如果有大量需要写入数据的业务场景，使用普通的redis分布式锁是没有问题的。但如果有些业务场景，写入的操作比较少，反而有大量读取的操作。这样直接使用普通的redis分布式锁，会不会有点浪费性能？

**读写锁**

读写锁的特点：

- **读与读是共享的，不互斥**
- **读与写互斥**
- **写与写互斥**

我们以redisson框架为例，它内部已经实现了读写锁的功能。读锁的伪代码如下：

```java
RReadWriteLock readWriteLock = redisson.getReadWriteLock("readWriteLock");
RLock rLock = readWriteLock.readLock();
try {
    rLock.lock();
    //业务操作
} catch (Exception e) {
    log.error(e);
} finally {
    rLock.unlock();
}
```

写锁的伪代码如下：

```java
RReadWriteLock readWriteLock = redisson.getReadWriteLock("readWriteLock");
RLock rLock = readWriteLock.writeLock();
try {
    rLock.lock();
    //业务操作
} catch (InterruptedException e) {
   log.error(e);
} finally {
    rLock.unlock();
}
```

将读锁和写锁分开，最大的好处是提升读操作的性能，因为读和读之间是共享的，不存在互斥性。而我们的实际业务场景中，绝大多数数据操作都是读操作。所以，如果提升了读操作的性能，也就会提升整个锁的性能。



**锁分段**

此外，为了减小锁的粒度，比较常见的做法是将大锁：`分段`。

比如在秒杀扣库存的场景中，现在的库存中有2000个商品，用户可以秒杀。为了防止出现超卖的情况，通常情况下，可以对库存加锁。如果有1W的用户竞争同一把锁，显然系统吞吐量会非常低。

为了提升系统性能，我们可以将库存分段，比如：分为100段，这样每段就有20个商品可以参与秒杀。

在秒杀的过程中，先把用户id获取hash值，然后除以100取模。模为1的用户访问第1段库存，模为2的用户访问第2段库存，模为3的用户访问第3段库存，后面以此类推，到最后模为100的用户访问第100段库存。

![Redis分布式锁-分段锁](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/Redis分布式锁-分段锁.png)

**注意**：将锁分段虽说可以提升系统的性能，但它也会让系统的复杂度提升不少。因为它需要引入额外的路由算法，跨段统计等功能。我们在实际业务场景中，需要综合考虑，不是说一定要将锁分段。



#### 锁超时问题

如果线程A加锁成功了，但是由于业务功能耗时时间很长，超过了设置的超时时间，这时候redis会自动释放线程A加的锁。

**解决方案：自动续期**

自动续期的功能是获取锁之后开启一个定时任务，每隔10秒判断一下锁是否存在，如果存在，则刷新过期时间。如果续期3次，也就是30秒之后，业务方法还是没有执行完，就不再续期了。

我们可以使用`TimerTask`类，来实现自动续期的功能：

```java
Timer timer = new Timer(); 
timer.schedule(new TimerTask() {
    @Override
    public void run(Timeout timeout) throws Exception {
      	//自动续期逻辑
    }
}, 10000, TimeUnit.MILLISECONDS);
```

获取锁之后，自动开启一个定时任务，每隔10秒钟，自动刷新一次过期时间。这种机制在redisson框架中，有个比较霸气的名字：`watch dog`，即传说中的`看门狗`。当然自动续期功能，我们还是优先推荐使用lua脚本实现，比如：

```lua
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then 
     redis.call('pexpire', KEYS[1], ARGV[1]);
     return 1; 
end;
return 0;
```

**需要**：在实现自动续期功能时，还需要设置一个总的过期时间，可以跟redisson保持一致，设置成30秒。如果业务代码到了这个总的过期时间，还没有执行完，就不再自动续期了。



#### 主从复制的问题

如果redis存在多个实例。比如：做了主从或使用了哨兵模式，基于redis的分布式锁的功能，就会出现问题。

比如锁A刚加锁成功master就挂了，还没来得及同步到slave上。这样会导致新master节点中的锁A丢失了。后面，如果有新的线程，使用锁A加锁，依然可以成功，分布式锁失效了。



**解决方案：RedissonRedLock**

RedissonRedLock解决问题的思路如下：

1. 需要搭建几套相互独立的redis环境，假如我们在这里搭建了5套
2. 每套环境都有一个redisson node节点
3. 多个redisson node节点组成了RedissonRedLock
4. 环境包含：单机、主从、哨兵和集群模式，可以是一种或者多种混合

在这里我们以主从为例，架构图如下：

![RedissonRedLock](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/RedissonRedLock.png)

RedissonRedLock加锁过程如下：

1. 获取所有的redisson node节点信息，循环向所有的redisson node节点加锁，假设节点数为N，例子中N等于5
2. 如果在N个节点当中，有N/2 + 1个节点加锁成功了，那么整个RedissonRedLock加锁是成功的
3. 如果在N个节点当中，小于N/2 + 1个节点加锁成功，那么整个RedissonRedLock加锁是失败的
4. 如果中途发现各个节点加锁的总耗时，大于等于设置的最大等待时间，则直接返回失败

从上面可以看出，使用Redlock算法，确实能解决多实例场景中，假如master节点挂了，导致分布式锁失效的问题。但也引出了一些新问题，比如：

- 需要额外搭建多套环境，申请更多的资源，需要评估一下成本和性价比
- 如果有N个redisson node节点，需要加锁N次，最少也需要加锁N/2+1次，才知道redlock加锁是否成功。显然，增加了额外的时间成本，有点得不偿失



**场景选择**

在实际业务场景，尤其是高并发业务中，RedissonRedLock其实使用的并不多。在分布式环境中，CAP是绕不过去的：一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。

- 如果你的实际业务场景，更需要的是**保证数据一致性**，那么请使用CP类型的分布式锁

  比如：zookeeper，它是基于磁盘的，性能可能没那么好，但数据一般不会丢

- 如果你的实际业务场景，更需要的是**保证数据高可用性**。那么请使用AP类型的分布式锁

  比如：redis，它是基于内存的，性能比较好，但有丢失数据的风险

其实，在绝大多数分布式业务场景中，使用redis分布式锁就够了，真的别太较真。因为数据不一致问题，可以通过最终一致性方案解决。但如果系统不可用了，对用户来说是暴击一万点伤害。



### LUA+SETNX+EXPIRE

先用`setnx`来抢锁，如果抢到之后，再用`expire`给锁设置一个过期时间，防止锁忘记了释放。

- **setnx(key, value)**

  `setnx` 的含义就是 `SET if Not Exists`，该方法是原子的。如果 `key` 不存在，则设置当前 `key` 为 `value` 成功，返回 `1`；如果当前 `key` 已经存在，则设置当前 `key` 失败，返回 `0`。

- **expire(key, seconds)**

  `expire` 设置过期时间，要注意的是 `setnx` 命令不能设置 `key` 的超时时间，只能通过 `expire()` 来对 `key` 设置。



**使用Lua脚本(SETNX+EXPIRE)**

可以使用Lua脚本来保证原子性（包含setnx和expire两条指令），加解锁代码如下：

```java
/**
 * 使用Lua脚本，脚本中使用setnex+expire命令进行加锁操作
 */
public boolean lock(Jedis jedis, String key, String uniqueId, int seconds) {
    String luaScript = "if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then" +
            		    "redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end";
    Object result = jedis.eval(luaScript, Collections.singletonList(key),
            Arrays.asList(uniqueId, String.valueOf(seconds)));
    return result.equals(1L);
}

/**
 * 使用Lua脚本进行解锁操纵，解锁的时候验证value值
 */
public boolean unlock(Jedis jedis, String key, String value) {
    String luaScript = "if redis.call('get',KEYS[1]) == ARGV[1] then " +
           			    "return redis.call('del',KEYS[1]) else return 0 end";
    return jedis.eval(luaScript, Collections.singletonList(key), Collections.singletonList(value)).equals(1L);
}
```



**STW**

如果在写文件过程中，发生了 FullGC，并且其时间跨度较长， 超过了锁超时的时间， 那么分布式就自动释放了。在此过程中，client2 抢到锁，写了文件。client1 的FullGC完成后，也继续写文件，**注意，此时 client1 的并没有占用锁**，此时写入会导致文件数据错乱，发生线程安全问题。这就是STW导致的锁过期问题。STW导致的锁过期问题，如下图所示：

![STW导致的锁过期问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/STW导致的锁过期问题.png)

STW导致的锁过期问题，大概的解决方案有：

- **方案一： 模拟CAS乐观锁的方式，增加版本号（如下图中的token）**

  ![模拟CAS乐观锁的方式-增加版本号](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/模拟CAS乐观锁的方式-增加版本号.png)

​	此方案如果要实现，需要调整业务逻辑，与之配合，所以会入侵代码。

- **方案二：watch dog自动延期机制**

  客户端1加锁的锁key默认生存时间才30秒，如果超过了30秒，客户端1还想一直持有这把锁，怎么办呢？简单！只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，**它是一个后台线程，会每隔10秒检查一下**，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。Redission采用的就是这种方案， 此方案不会入侵业务代码。



### SET-NX-EX

**方案**：`SET key value [EX seconds] [PX milliseconds] [NX|XX]`

- `EX second` ：设置键的过期时间为 `second` 秒。 `SET key value EX second` 效果等同于 `SETEX key second value` 
- `PX millisecond` ：设置键的过期时间为 `millisecond` 毫秒。 `SET key value PX millisecond` 效果等同于 `PSETEX key millisecond value` 
- `NX` ：只在键不存在时，才对键进行设置操作。 `SET key value NX` 效果等同于 `SETNX key value` 
- `XX` ：只在键已经存在时，才对键进行设置操作

客户端执行以上的命令：

- 如果服务器返回 `OK` ，那么这个客户端获得锁
- 如果服务器返回 `NIL` ，那么客户端获取锁失败，可以在稍后再重试



**① 加锁**：使用redis命令 set key value NX EX max-lock-time 实现加锁

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
private static final String SUCCESS = "OK";

 /**
  * 加锁操作
  * @param key 锁标识
  * @param value 客户端标识
  * @param timeOut 过期时间
  */
 public Boolean lock(String key,String value,Long timeOut){
     String var1 = jedis.set(key,value,"NX","EX",timeOut);
     if(LOCK_SUCCESS.equals(var1)){
         return true;
     }
     return false;
 }
```

- 加锁操作 `jedis.set(key,value,"NX","EX",timeout)`【保证加锁的原子操作】
- `key`是`redis`的`key`值作为锁的标识，`value`在作为客户端的标识，只有`key-value`都比配才有删除锁的权利【保证安全性】
- 通过`timeout`设置过期时间保证不会出现死锁【避免死锁】
- `NX`：只有这个`key`不存才的时候才会进行操作，`if not exists`
- `EX`：设置`key`的过期时间为秒，具体时间由第`5`个参数决定，过期时间设置的合理有效期需要根据业务具体决定，总的原则是任务执行`time*3`



**② 解锁**：使用redis命令 EVAL 实现解锁

```java
Jedis jedis = new Jedis("127.0.0.1", 6379);
private static final String SUCCESS = "OK";

 /**
  * 加锁操作
  * @param key 锁标识
  * @param value 客户端标识
  * @param timeOut 过期时间
  */
 public Boolean lock(String key,String value,Long timeOut){
     String var1 = jedis.set(key,value,"NX","EX",timeOut);
     if(LOCK_SUCCESS.equals(var1)){
         return true;
     }
     return false;
 }
```

- luaScript 这个字符串是个lua脚本，代表的意思是如果根据key拿到的value跟传入的value相同就执行del，否则就返回0【保证安全性】
- jedis.eval(String,list,list);这个命令就是去执行lua脚本，KEYS的集合就是第二个参数，ARGV的集合就是第三参数【保证解锁的原子操作】



**③ 重试**

如果在业务中去拿锁如果没有拿到是应该阻塞着一直等待还是直接返回，这个问题其实可以写一个重试机制，根据重试次数和重试时间做一个循环去拿锁，当然这个重试的次数和时间设多少合适，是需要根据自身业务去衡量的。

```java
/**
 * 重试机制
 * @param key 锁标识
 * @param value 客户端标识
 * @param timeOut 过期时间
 * @param retry 重试次数
 * @param sleepTime 重试间隔时间
 * @return
 */
public Boolean lockRetry(String key,String value,Long timeOut,Integer retry,Long sleepTime){
    Boolean flag = false;
    try {
        for (int i=0;i<retry;i++){
            flag = lock(key,value,timeOut); 
            if(flag){
                break; 
            } 
            Thread.sleep(sleepTime); 
        } 
    }catch (Exception e){ 
        e.printStackTrace(); 
    } 
    return flag; 
}
```

 

### Redisson

Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。

![Redisson](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/Redisson.jpg)

**特性功能**

- 支持 Redis 单节点（single）模式、哨兵（sentinel）模式、主从（Master/Slave）模式以及集群（Redis Cluster）模式
- 程序接口调用方式采用异步执行和异步流执行两种方式
- 数据序列化，Redisson 的对象编码类是用于将对象进行序列化和反序列化，以实现对该对象在 Redis 里的读取和存储
- 单个集合数据分片，在集群模式下，Redisson 为单个 Redis 集合类型提供了自动分片的功能
- 提供多种分布式对象，如：Object Bucket，Bitset，AtomicLong，Bloom Filter 和 HyperLogLog 等
- 提供丰富的分布式集合，如：Map，Multimap，Set，SortedSet，List，Deque，Queue 等
- 分布式锁和同步器的实现，可重入锁（Reentrant Lock），公平锁（Fair Lock），联锁（MultiLock），红锁（Red Lock），信号量（Semaphonre），可过期性信号锁（PermitExpirableSemaphore）等
- 提供先进的分布式服务，如分布式远程服务（Remote Service），分布式实时对象（Live Object）服务，分布式执行服务（Executor Service），分布式调度任务服务（Schedule Service）和分布式映射归纳服务（MapReduce）



**Watch dog**

![Redisson分布式锁](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/Redisson分布式锁.jpg)

总体的Redisson框架的分布式锁类型大致如下：

- **可重入锁**
- **公平锁**
- **联锁**
- **红锁**
- **读写锁**
- **信号量**
- **可过期信号量**
- **闭锁（/倒数闩）**



**实现方案**

添加依赖

```xml
<!-- 方式一：redisson-java -->
<dependency>	
    <groupId>org.redisson</groupId>	
    <artifactId>redisson</artifactId>	
    <version>3.11.4</version>	
</dependency>

<!-- 方式二：redisson-springboot -->
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson-spring-boot-starter</artifactId>
    <version>3.11.4</version>
</dependency>
```

定义接口

```java
import org.redisson.api.RLock;
import java.util.concurrent.TimeUnit;

public interface DistributedLocker {

    RLock lock(String lockKey);

    RLock lock(String lockKey, int timeout);

    RLock lock(String lockKey, TimeUnit unit, int timeout);

    boolean tryLock(String lockKey, TimeUnit unit, int waitTime, int leaseTime);

    void unlock(String lockKey);

    void unlock(RLock lock);
    
}
```

实现分布式锁

```java
import org.redisson.api.RLock;
import org.redisson.api.RedissonClient;

import java.util.concurrent.TimeUnit;

public class RedissonDistributedLocker implements DistributedLocker{

    private RedissonClient redissonClient;

    @Override
    public RLock lock(String lockKey) {
        RLock lock = redissonClient.getLock(lockKey);
        lock.lock();
        return lock;
    }

    @Override
    public RLock lock(String lockKey, int leaseTime) {
        RLock lock = redissonClient.getLock(lockKey);
        lock.lock(leaseTime, TimeUnit.SECONDS);
        return lock;
    }

    @Override
    public RLock lock(String lockKey, TimeUnit unit ,int timeout) {
        RLock lock = redissonClient.getLock(lockKey);
        lock.lock(timeout, unit);
        return lock;
    }

    @Override
    public boolean tryLock(String lockKey, TimeUnit unit, int waitTime, int leaseTime) {
        RLock lock = redissonClient.getLock(lockKey);
        try {
            return lock.tryLock(waitTime, leaseTime, unit);
        } catch (InterruptedException e) {
            return false;
        }
    }

    @Override
    public void unlock(String lockKey) {
        RLock lock = redissonClient.getLock(lockKey);
        lock.unlock();
    }

    @Override
    public void unlock(RLock lock) {
        lock.unlock();
    }

    public void setRedissonClient(RedissonClient redissonClient) {
        this.redissonClient = redissonClient;
    }
    
}
```



**高可用的RedLock（红锁）原理**

RedLock算法思想是不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，n / 2 + 1，必须在大多数redis节点上都成功创建锁，才能算这个整体的RedLock加锁成功，避免说仅仅在一个redis实例上加锁而带来的问题。



## Zookeeper

### Apache-Curator

![InterProcessMutex](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/InterProcessMutex.png)

如上借助于临时顺序节点，可以避免同时多个节点的并发竞争锁，缓解了服务端压力。这种实现方式所有加锁请求都进行排队加锁，是公平锁的具体实现。Apache-Curator中提供的常见锁有如下：

- **InterProcessMutex**：就是公平锁的实现。可重入、独占锁
- **InterProcessSemaphoreMutex**：不可重入、独占锁
- **InterProcessReadWriteLock**：读写锁
- **InterProcessSemaphoreV2**：共享信号量
- **InterProcessMultiLock**：多重共享锁 （将多个锁作为单个实体管理的容器）



### 使用案例

```java
import java.util.Arrays;
import java.util.Collection;
import java.util.HashSet;
import java.util.Set;
import java.util.concurrent.TimeUnit;

import org.apache.curator.RetryPolicy;
import org.apache.curator.framework.CuratorFramework;
import org.apache.curator.framework.CuratorFrameworkFactory;
import org.apache.curator.framework.recipes.locks.InterProcessLock;
import org.apache.curator.framework.recipes.locks.InterProcessMultiLock;
import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.apache.curator.framework.recipes.locks.InterProcessReadWriteLock;
import org.apache.curator.framework.recipes.locks.InterProcessSemaphoreMutex;
import org.apache.curator.framework.recipes.locks.InterProcessSemaphoreV2;
import org.apache.curator.framework.recipes.locks.Lease;
import org.apache.curator.retry.ExponentialBackoffRetry;
import org.apache.curator.utils.CloseableUtils;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;

public class DistributedLockDemo {

	// ZooKeeper 锁节点路径, 分布式锁的相关操作都是在这个节点上进行
	private final String lockPath = "/distributed-lock";
	// ZooKeeper 服务地址, 单机格式为:(127.0.0.1:2181),
	// 集群格式为:(127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183)
	private String connectString="127.0.0.1:2181";
	// Curator 客户端重试策略
	private RetryPolicy retry;
	// Curator 客户端对象
	private CuratorFramework client1;
	// client2 用户模拟其他客户端
	private CuratorFramework client2;

	// 初始化资源
	@Before
	public void init() throws Exception {
		// 重试策略
		// 初始休眠时间为 1000ms, 最大重试次数为 3
		retry = new ExponentialBackoffRetry(1000, 3);
		// 创建一个客户端, 60000(ms)为 session 超时时间, 15000(ms)为链接超时时间
		client1 = CuratorFrameworkFactory.newClient(connectString, 60000, 15000, retry);
		client2 = CuratorFrameworkFactory.newClient(connectString, 60000, 15000, retry);
		// 创建会话
		client1.start();
		client2.start();
	}

	// 释放资源
	@After
	public void close() {
		CloseableUtils.closeQuietly(client1);
	}

	/**
	 * InterProcessMutex：可重入、独占锁
	 */
	@Test
	public void sharedReentrantLock() throws Exception {
		// 创建可重入锁
		InterProcessMutex lock1 = new InterProcessMutex(client1, lockPath);
		// lock2 用于模拟其他客户端
		InterProcessMutex lock2 = new InterProcessMutex(client2, lockPath);
		
		// lock1 获取锁
		lock1.acquire();
		try {
			// lock1 第2次获取锁
			lock1.acquire();
			try {
				// lock2 超时获取锁, 因为锁已经被 lock1 客户端占用, 所以lock2获取锁失败, 需要等 lock1 释放
				Assert.assertFalse(lock2.acquire(2, TimeUnit.SECONDS));
			} finally {
				lock1.release();
			}
		} finally {
			// 重入锁获取与释放需要一一对应, 如果获取 2 次, 释放 1 次, 那么该锁依然是被占用, 
			// 如果将下面这行代码注释, 那么会发现下面的 lock2
			// 获取锁失败
			lock1.release();
		}
		
		// 在 lock1 释放后, lock2 能够获取锁
		Assert.assertTrue(lock2.acquire(2, TimeUnit.SECONDS));
		lock2.release();
	}
	
	/**
	 * InterProcessSemaphoreMutex： 不可重入、独占锁
	 */
	@Test
	public void sharedLock() throws Exception {
		InterProcessSemaphoreMutex lock1 = new InterProcessSemaphoreMutex(client1, lockPath);
		// lock2 用于模拟其他客户端
		InterProcessSemaphoreMutex lock2 = new InterProcessSemaphoreMutex(client2, lockPath);

		// 获取锁对象
		lock1.acquire();

		// 测试是否可以重入
		// 因为锁已经被获取, 所以返回 false
		Assert.assertFalse(lock1.acquire(2, TimeUnit.SECONDS));// lock1 返回是false
		Assert.assertFalse(lock2.acquire(2, TimeUnit.SECONDS));// lock2 返回是false

		// lock1 释放锁
		lock1.release();

		// lock2 尝试获取锁成功, 因为锁已经被释放
		Assert.assertTrue(lock2.acquire(2, TimeUnit.SECONDS));// 返回是true
		lock2.release();
		System.out.println("测试结束");
	}

	/**
	 * InterProcessReadWriteLock：读写锁.
	 * 特点：读写锁、可重入
	 */
	@Test
	public void sharedReentrantReadWriteLock() throws Exception {
		// 创建读写锁对象, Curator 以公平锁的方式进行实现
		InterProcessReadWriteLock lock1 = new InterProcessReadWriteLock(client1, lockPath);
		// lock2 用于模拟其他客户端
		InterProcessReadWriteLock lock2 = new InterProcessReadWriteLock(client2, lockPath);
		
		// 使用 lock1 模拟读操作
		// 使用 lock2 模拟写操作
		// 获取读锁(使用 InterProcessMutex 实现, 所以是可以重入的)
		final InterProcessLock readLock = lock1.readLock();
		// 获取写锁(使用 InterProcessMutex 实现, 所以是可以重入的)
		final InterProcessLock writeLock = lock2.writeLock();

		/**
		 * 读写锁测试对象
		 */
		class ReadWriteLockTest {
			// 测试数据变更字段
			private Integer testData = 0;
			private Set<Thread> threadSet = new HashSet<>();

			// 写入数据
			private void write() throws Exception {
				writeLock.acquire();
				try {
					Thread.sleep(10);
					testData++;
					System.out.println("写入数据 \t" + testData);
				} finally {
					writeLock.release();
				}
			}

			// 读取数据
			private void read() throws Exception {
				readLock.acquire();
				try {
					Thread.sleep(10);
					System.out.println("读取数据 \t" + testData);
				} finally {
					readLock.release();
				}
			}

			// 等待线程结束, 防止 test 方法调用完成后, 当前线程直接退出, 导致控制台无法输出信息
			public void waitThread() throws InterruptedException {
				for (Thread thread : threadSet) {
					thread.join();
				}
			}

			// 创建线程方法
			private void createThread(final int type) {
				Thread thread = new Thread(new Runnable() {
					@Override
					public void run() {
						try {
							if (type == 1) {
								write();
							} else {
								read();
							}
						} catch (Exception e) {
							e.printStackTrace();
						}
					}
				});
				threadSet.add(thread);
				thread.start();
			}

			// 测试方法
			public void test() {
				for (int i = 0; i < 5; i++) {
					createThread(1);
				}
				for (int i = 0; i < 5; i++) {
					createThread(2);
				}
			}
		}

		ReadWriteLockTest readWriteLockTest = new ReadWriteLockTest();
		readWriteLockTest.test();
		readWriteLockTest.waitThread();
	}

	/**
	 * InterProcessSemaphoreV2 共享信号量
	 */
	@Test
	public void semaphore() throws Exception {
		// 创建一个信号量, Curator 以公平锁的方式进行实现
		InterProcessSemaphoreV2 semaphore1 = new InterProcessSemaphoreV2(client1, lockPath, 6);
		// semaphore2 用于模拟其他客户端
		InterProcessSemaphoreV2 semaphore2 = new InterProcessSemaphoreV2(client2, lockPath, 6);

		// 获取一个许可
		Lease lease1 = semaphore1.acquire();
		Assert.assertNotNull(lease1);
		// semaphore.getParticipantNodes() 会返回当前参与信号量的节点列表, 俩个客户端所获取的信息相同
		Assert.assertEquals(semaphore1.getParticipantNodes(), semaphore2.getParticipantNodes());

		// 超时获取一个许可
		Lease lease2 = semaphore2.acquire(2, TimeUnit.SECONDS);
		Assert.assertNotNull(lease2);
		Assert.assertEquals(semaphore1.getParticipantNodes(), semaphore2.getParticipantNodes());

		// 获取多个许可, 参数为许可数量
		Collection<Lease> leases = semaphore1.acquire(2);
		Assert.assertTrue(leases.size() == 2);
		Assert.assertEquals(semaphore1.getParticipantNodes(), semaphore2.getParticipantNodes());

		// 超时获取多个许可, 第一个参数为许可数量
		Collection<Lease> leases2 = semaphore2.acquire(2, 2, TimeUnit.SECONDS);
		Assert.assertTrue(leases2.size() == 2);
		Assert.assertEquals(semaphore1.getParticipantNodes(), semaphore2.getParticipantNodes());

		// 目前 semaphore 已经获取 3 个许可, semaphore2 也获取 3 个许可, 加起来为 6 个, 所以他们无法再进行许可获取
		Assert.assertNull(semaphore1.acquire(2, TimeUnit.SECONDS));
		Assert.assertNull(semaphore2.acquire(2, TimeUnit.SECONDS));

		// 释放一个许可
		semaphore1.returnLease(lease1);
		semaphore2.returnLease(lease2);
		// 释放多个许可
		semaphore1.returnAll(leases);
		semaphore2.returnAll(leases2);
	}

	/**
	 * InterProcessMutex ：可重入、独占锁
	 * InterProcessSemaphoreMutex ： 不可重入、独占锁
	 * InterProcessMultiLock： 多重共享锁（将多个锁作为单个实体管理的容器）
	 */
	@Test
	public void multiLock() throws Exception {
		InterProcessMutex mutex = new InterProcessMutex(client1, lockPath);
		InterProcessSemaphoreMutex semaphoreMutex = new InterProcessSemaphoreMutex(client2, lockPath);
		//将上面的两种锁入到其中
		InterProcessMultiLock multiLock = new InterProcessMultiLock(Arrays.asList(mutex, semaphoreMutex));
		// 获取参数集合中的所有锁
		multiLock.acquire();
		// 因为存在一个不可重入锁, 所以整个 multiLock 不可重入
		Assert.assertFalse(multiLock.acquire(2, TimeUnit.SECONDS));
		// mutex 是可重入锁, 所以可以继续获取锁
		Assert.assertTrue(mutex.acquire(2, TimeUnit.SECONDS));
		// semaphoreMutex  是不可重入锁, 所以获取锁失败
		Assert.assertFalse(semaphoreMutex.acquire(2, TimeUnit.SECONDS));
		// 释放参数集合中的所有锁
		multiLock.release();
		// interProcessLock2 中的锁已经释放, 所以可以获取
		Assert.assertTrue(semaphoreMutex.acquire(2, TimeUnit.SECONDS));
	}
}
```

对于Java中的锁大家肯定都很熟悉，在Java中synchronized关键字和ReentrantLock可重入锁在我们的代码中是经常见的，一般我们用其在多线程环境中控制对资源的并发访问，但是随着分布式的快速发展，本地的加锁往往不能满足我们的需要，在我们的分布式环境中上面加锁的方法就会失去作用。为了在分布式环境中也能实现本地锁的效果，人们提出了分布式锁的概念。

# 分布式锁

## 分布式锁场景

一般需要使用分布式锁的场景如下：

- 效率：使用分布式锁可以避免不同节点重复相同的工作，比如避免重复执行定时任务等；
- 正确性：使用分布式锁同样可以避免破坏数据正确性，如果两个节点在同一条数据上面操作，可能会出现并发问题。

## 分布式锁特点

一个完善的分布式锁需要满足以下特点：

- 互斥性：互斥是所得基本特性，分布式锁需要按需求保证线程或节点级别的互斥。；
- 可重入性：同一个节点或同一个线程获取锁，可以再次重入获取这个锁；
- 锁超时：支持锁超时释放，防止某个节点不可用后，持有的锁无法释放；
- 高效性：加锁和解锁的效率高，可以支持高并发；
- 高可用：需要有高可用机制预防锁服务不可用的情况，如增加降级；
- 阻塞性：支持阻塞获取锁和非阻塞获取锁两种方式；
- 公平性：支持公平锁和非公平锁两种类型的锁，公平锁可以保证安装请求锁的顺序获取锁，而非公平锁不可以。

## 分布式锁的实现

分布式锁常见的实现有三种实现，下文我们会一一介绍这三种锁的实现方式：

- 基于数据库的分布式锁；
- 基于Redis的分布式锁；
- 基于Zookeeper的分布式锁。

## 基于数据库的分布式锁

基于数据库的分布式锁可以有不同的实现方式，本文会介绍作者在实际生产中使用的一种数据库非阻塞分布式锁的实现方案。

### 方案概览

我们上面列举出了分布式锁需要满足的特点，使用数据库实现分布式锁也需要满足这些特点，下面我们来一一介绍实现方法：

- 互斥性：通过数据库update的原子性达到两次获取锁之间的互斥性；
- 可重入性：在数据库中保留一个字段存储当前锁的持有者；
- 锁超时：在数据库中存储锁的获取时间点和超时时长；
- 高效性：数据库本身可以支持比较高的并发；
- 高可用：可以增加主从数据库逻辑，提升数据库的可用性；
- 阻塞性：可以通过看门狗轮询的方式实现线程的阻塞；
- 公平性：可以添加锁队列，不过不建议，实现起来比较复杂。

### 表结构设计

数据库的表名为lock，各个字段的定义如下所示：

| 字段名名称    | 字段类型    | 说明                                                         |
| ------------- | ----------- | ------------------------------------------------------------ |
| lock_key      | varchar     | 锁的唯一标识符号                                             |
| lock_time     | timestample | 加锁的时间                                                   |
| lock_duration | integer     | 锁的超时时长，单位可以业务自定义，通常为秒                   |
| lock_owner    | varchar     | 锁的持有者，可以是节点或线程的唯一标识，不同可重入粒度的锁有不同的含义 |
| locked        | boolean     | 当前锁是否被占有                                             |

### 获取锁的SQL语句

获取锁的SQL语句分不同的情况，如果锁不存在，那么首先需要创建锁，并且创建锁的线程可以获取锁：

```sql
insert into lock(lock_key,lock_time,lock_duration,lock_owner,locked) values ('xxx',now(),1000,'ownerxxx',true)
```

如果锁已经存在，那么就尝试更新锁的信息，如果更新成功则表示获取锁成功，更新失败则表示获取锁失败。

```sql
update lock set 
    locked = true, 
    lock_owner = 'ownerxxxx', 
    lock_time = now(), 
    lock_duration = 1000
where
    lock_key='xxx' and(
    lock_owner = 'ownerxxxx' or
    locked = false or
    date_add(lock_time, interval lock_duration second) > now())
```

### 释放锁的SQL语句

当用户使用完锁需要释放的时候，可以直接更新locked标识位为false。

```sql
update lock set 
    locked = false, 
where
    lock_key='xxx' and
    lock_owner = 'ownerxxxx' and
    locked = true
```

### 看门狗

通过上面的步骤，我们可以实现获取锁和释放锁，那么看门狗又是做什么的呢？

大家想象一下，如果用户获取锁到释放锁之间的时间大于锁的超时时间，是不是会有问题？是不是可能会出现多个节点同时获取锁的情况？这个时候就需要看门狗了，看门狗可以通过定时任务不断刷新锁的获取事件，从而在用户获取锁到释放锁期间保持一直持有锁。

## 基于Redis的分布式锁

Redis的Java客户端Redisson实现了分布式锁，我们可以通过类似ReentrantLock的加锁-释放锁的逻辑来实现分布式锁。

```java
RLock disLock = redissonClient.getLock("DISLOCK");
disLock.lock();
try {
    // 业务逻辑
} finally {
    // 无论如何, 最后都要解锁
    disLock.unlock();
}
```

### Redisson分布式锁的底层原理

如下图为Redisson客户端加锁和释放锁的逻辑：

![Redisson客户端加锁和释放锁](https://oscimg.oschina.net/oscnet/up-42dfdc1b13185267fd05fe45737655ece70.jpg)

### 加锁机制

从上图中可以看出来，Redisson客户端需要获取锁的时候，要发送一段Lua脚本到Redis集群执行，为什么要用Lua脚本呢？因为一段复杂的业务逻辑，可以通过封装在Lua脚本中发送给Redis，保证这段复杂业务逻辑执行的原子性。

**Lua源码分析**：如下为Redisson加锁的lua源码，接下来我们会对源码进行分析。

**源码入参**：Lua脚本有三个输入参数：KEYS[1]、ARGV[1]和ARGV[2]，含义如下：

- KEYS[1]代表的是加锁的Key，例如RLock lock = redisson.getLock("myLock")中的“myLock”；
- ARGV[1]代表的就是锁Key的默认生存时间，默认30秒；
- ARGV[2]代表的是加锁的客户端的ID，类似于下面这样的：8743c9c0-0795-4907-87fd-6c719a6b4586:1。

Lua脚本及加锁步骤如下代码块所示，可以看出其大致原理为：

- 锁不存在的时候，创建锁并设置过期时间；
- 锁存在的时候，如果是重入场景则刷新锁的过期事件；
- 否则返回加锁失败和锁的过期时间。

```lua
-- 判断锁是不是存在
if (redis.call('exists', KEYS[1]) == 0) then 
    -- 添加锁，并且设置客户端和初始锁重入次数
    redis.call('hincrby', KEYS[1], ARGV[2], 1); 
    -- 设置锁的超时事件 
    redis.call('pexpire', KEYS[1], ARGV[1]);  
    -- 返回加锁成功
    return nil;  
end;  
-- 判断当前锁的持有者是不是请求锁的请求者
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then  
    -- 当前锁被请求者持有，重入锁，增加锁重入次数
    redis.call('hincrby', KEYS[1], ARGV[2], 1);  
    -- 刷新锁的过期时间
    redis.call('pexpire', KEYS[1], ARGV[1]);  
    -- 返回加锁成功
    return nil;  
end;  
-- 返回当前锁的过期时间
return redis.call('pttl', KEYS[1]);
```

### 看门狗逻辑

客户端1加锁的锁Key默认生存时间才30秒，如果超过了30秒，客户端1还想一直持有这把锁，怎么办呢？只要客户端1加锁成功，就会启动一个watchdog看门狗，这个后台线程，会每隔10秒检查一下，如果客户端1还持有锁Key，就会不断的延长锁Key的生存时间。

### 释放锁机制

如果执行lock.unlock()，就可以释放分布式锁，此时的业务逻辑也是非常简单的。就是每次都对myLock数据结构中的那个加锁次数减1。

如果发现加锁次数是0了，说明这个客户端已经不再持有锁了，此时就会用：“del myLock”命令，从Redis里删除这个Key。

而另外的客户端2就可以尝试完成加锁了。这就是所谓的分布式锁的开源Redisson框架的实现机制。

一般我们在生产系统中，可以用Redisson框架提供的这个类库来基于Redis进行分布式锁的加锁与释放锁。

### Redisson分布式锁的缺陷

Redis分布式锁会有个缺陷，就是在Redis哨兵模式下:

1. 客户端1对某个master节点写入了redisson锁，此时会异步复制给对应的slave节点。但是这个过程中一旦发生master节点宕机，主备切换，slave节点从变为了master节点。
2. 客户端2来尝试加锁的时候，在新的master节点上也能加锁，此时就会导致多个客户端对同一个分布式锁完成了加锁。
3. 系统在业务语义上一定会出现问题，导致各种脏数据的产生。

这个缺陷导致在哨兵模式或者主从模式下，如果master实例宕机的时候，可能导致多个客户端同时完成加锁。

## 基于Zookeeper的分布式锁

Zookeeper实现的分布式锁适用于引入Zookeeper的服务，如下所示，有两个服务注册到Zookeeper，并且都需要获取Zookeeper上的分布式锁，流程式什么样的呢？

![Zookeeper的分布式锁-1](https://oscimg.oschina.net/oscnet/up-82d1ec07ded8abba255afb822a465678ce2.jpg)

### 步骤1

假设客户端A抢先一步，对ZK发起了加分布式锁的请求，这个加锁请求是用到了ZK中的一个特殊的概念，叫做“临时顺序节点”。简单来说，就是直接在"my_lock"这个锁节点下，创建一个顺序节点，这个顺序节点有ZK内部自行维护的一个节点序号。

- 比如第一个客户端来获取一个顺序节点，ZK内部会生成名称xxx-000001。
- 然后第二个客户端来获取一个顺序节点，ZK内部会生成名称xxx-000002。

最后一个数字都是依次递增的，从1开始逐次递增。ZK会维护这个顺序。所以客户端A先发起请求，就会生成出来一个顺序节点，如下所示：

![Zookeeper的分布式锁-2](https://oscimg.oschina.net/oscnet/up-fefcdbf827833e58d028549f29c7c6720fb.jpg)

客户端A发起了加锁请求，会先加锁的node下生成一个临时顺序节点。因为客户端A是第一个发起请求，所以节点名称的最后一个数字是"1"。客户端A创建完好顺序节后，会查询锁下面所有的节点，按照末尾数字升序排序，判断当前节点的是不是第一个节点，如果是第一个节点则加锁成功。

![Zookeeper的分布式锁-3](https://oscimg.oschina.net/oscnet/up-c8dac4184fbb6248ade08c531a983732b88.jpg)

### 步骤2

客户端A都加完锁了，客户端B过来想要加锁了，此时也会在锁节点下创建一个临时顺序节点，节点名称的最后一个数字是"2"。

![Zookeeper的分布式锁-4](https://oscimg.oschina.net/oscnet/up-28cd8644a089abcd294d55c94a114716977.jpg)

客户端B会判断加锁逻辑，查询锁节点下的所有子节点，按序号顺序排列，此时第一个是客户端A创建的那个顺序节点，序号为"01"的那个。所以加锁失败。加锁失败了以后，客户端B就会通过ZK的API对他的顺序节点的上一个顺序节点加一个监听器。ZK天然就可以实现对某个节点的监听。

![Zookeeper的分布式锁-5](https://oscimg.oschina.net/oscnet/up-091fc1a08f35e7aedead721a5c5e946b0d0.jpg)

### 步骤3

客户端A加锁之后，可能处理了一些代码逻辑，然后就会释放锁。Zookeeper释放锁其实就是把客户端A创建的顺序节点`zk_random_000001`删除。

![Zookeeper的分布式锁-6](https://oscimg.oschina.net/oscnet/up-757cf6fa5f5c76bc17703b1d77c66508988.jpg)

删除客户端A的节点之后，Zookeeper会负责通知监听这个节点的监听器，也就是客户端B之前添加监听器。客户端B的监听器知道了上一个顺序节点被删除，也就是排在他之前的某个客户端释放了锁。此时，就会客户端B会重新尝试去获取锁，也就是获取锁节点下的子节点集合，判断自身是不是第一个节点，从而获取锁。

![Zookeeper的分布式锁-7](https://oscimg.oschina.net/oscnet/up-3d47e2dd8be55465e915b4197c84b2e1b8a.jpg)

## 三种锁的优缺点

**基于数据库的分布式锁**：

- 数据库并发性能较差；
- 阻塞式锁实现比较复杂；
- 公平锁实现比较复杂。

**基于Redis的分布式锁**：

- 主从切换的情况下可能出现多客户端获取锁的情况；
- Lua脚本在单机上具有原子性，主从同步时不具有原子性。

**基于Zookeeper的分布式锁**：

- 需要引入Zookeeper集群，比较重量级；
- 分布式锁的可重入粒度只能是节点级别；
