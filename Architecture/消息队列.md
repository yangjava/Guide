# 消息队列

## 痛点问题

### 总耗时长

有些复杂业务系统，一次用户请求可能会同步调用N个系统接口，需要等待所有的接口都返回了，才能真正的获取执行结果。

![消息队列-痛点1](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-痛点1.png)

这种同步接口调用的方式`总耗时比较长`，非常影响用户的体验，特别是在网络不稳定的情况下，极容易出现接口超时问题。



### 耦合性高

很多复杂的业务系统，一般都会拆分成多个子系统。我们在这里以用户下单为例，请求会先通过订单系统，然后分别调用：支付系统、库存系统、积分系统 和 物流系统。

![消息队列-痛点2](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-痛点2.png)

系统之间`耦合性太高`，如果调用的任何一个子系统出现异常，整个请求都会异常，对系统的稳定性非常不利。



### 突发流量

有时候为了吸引用户，我们会搞一些活动，比如秒杀等。

![消息队列-痛点3-业务场景](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-痛点3-业务场景.png)

如果用户少还好，不会影响系统的稳定性。但如果用户突增，一时间所有的请求都到数据库，可能会导致数据库无法承受这么大的压力，响应变慢或者直接挂掉。

![消息队列-痛点3-请求过多](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-痛点3-请求过多.png)

对于这种 `突发流量`，无法保证系统的稳定性。



## 功能特性

对于上面传统模式的三类问题，使用MQ就能轻松解决。

### 异步

同步接口调用导致响应时间长的问题，使用MQ之后，将同步调用改成异步，能够显著减少系统响应时间。

![消息队列-功能-异步](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-功能-异步.png)

系统A作为消息的生产者，在完成本职工作后，就能直接返回结果了。而无需等待消息消费者的返回，它们最终会独立完成所有的业务功能。这样能避免`总耗时比较长`，从而影响用户的体验的问题。



### 解耦

子系统间耦合性太大的问题，使用MQ之后，我们只需要依赖于MQ，避免了各个子系统间的强依赖问题。

![消息队列-功能-解耦](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-功能-解耦.png)

订单系统作为消息生产者，保证它自己没有异常即可，不会受到支付系统等业务子系统的异常影响，并且各个消费者业务子系统之间，也互不影响。这样就把之前复杂的业务子系统的依赖关系，转换为只依赖于MQ的简单依赖，从而显著的降低了系统间的耦合度。



### 消峰

由于突然出现的`突发流量`，导致系统不稳定的问题。使用MQ后，能够起到消峰的作用。

![消息队列-功能-消峰](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-功能-消峰.png)

订单系统接收到用户请求之后，将请求直接发送到MQ，然后订单消费者从MQ中消费消息，做写库操作。如果出现`突发流量`的情况，由于消费者的消费能力有限，会按照自己的节奏来消费消息，多的请求不处理，保留在MQ的队列中，不会对系统的稳定性造成影响。



## 引发问题

引入MQ后让我们子系统间耦合性降低了，异步处理机制减少了系统的响应时间，同时能够有效的应对`突发流量`问题，提升系统的稳定性。但是引入MQ同时也会带来一些问题。

### 重复消息

重复消费问题可以说是MQ中普遍存在的问题，不管你用哪种MQ都无法避免。有哪些场景会出现重复的消息呢？

- **消息生产者产生了重复的消息**
- **Kafka和RocketMQ的offset被回调了**
- **消息消费者确认失败**
- **消息消费者确认时超时了**
- **业务系统主动发起重试**

![消息队列-问题-重复消息问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-问题-重复消息问题.png)

如果重复消息不做正确的处理，会对业务造成很大的影响，产生重复的数据，或者导致数据异常，比如会员系统多开通了一个月的会员。



### 数据一致性

很多时候，如果MQ的消费者业务处理异常的话，就会出现数据一致性问题。比如：一个完整的业务流程是，下单成功之后，送100个积分。下单写库了，但是消息消费者在送积分的时候失败了，就会造成`数据不一致`的情况，即该业务流程的部分数据写库了，另外一部分没有写库。

![消息队列-问题-数据一致性问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-问题-数据一致性问题.png)

如果下单和送积分在同一个事务中，要么同时成功，要么同时失败，是不会出现数据一致性问题的。但由于跨系统调用，为了性能考虑，一般不会使用强一致性的方案，而改成达成最终一致性即可。



### 消息丢失

同样消息丢失问题，也是MQ中普遍存在的问题，不管你用哪种MQ都无法避免。有哪些场景会出现消息丢失问题呢？

- **消息生产者发生消息时，由于网络原因，发生到MQ失败了**
- **MQ服务器持久化时，磁盘出现异常**
- **Kafka和RocketMQ的offset被回调时，略过了很多消息**
- **消息消费者刚读取消息，已经ACK确认了，但业务还没处理完，服务就被重启了**

导致消息丢失问题的原因挺多的，`生产者`、`MQ服务器`、`消费者` 都有可能产生问题，在这里就不一一列举了。最终的结果会导致消费者无法正确的处理消息，而导致数据不一致的情况。



### 消息顺序

有些业务数据是有状态的，比如订单有：下单、支付、完成、退货等状态，如果订单数据作为消息体，就会涉及顺序问题了。如果消费者收到同一个订单的两条消息，第一条消息的状态是下单，第二条消息的状态是支付，这是没问题的。但如果第一条消息的状态是支付，第二条消息的状态是下单就会有问题了，没有下单就先支付了？

![消息队列-问题-消息顺序问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-问题-消息顺序问题.png)

消息顺序问题是一个非常棘手的问题，比如：

- `Kafka`同一个`partition`中能保证顺序，但是不同的`partition`无法保证顺序
- `RabbitMQ`的同一个`queue`能够保证顺序，但是如果多个消费者同一个`queue`也会有顺序问题

如果消费者使用多线程消费消息，也无法保证顺序。如果消费消息时同一个订单的多条消息中，中间的一条消息出现异常情况，顺序将会被打乱。还有如果生产者发送到MQ中的路由规则，跟消费者不一样，也无法保证顺序。



### 消息堆积

如果消息消费者读取消息的速度，能够跟上消息生产者的节奏，那么整套MQ机制就能发挥最大作用。但是很多时候，由于某些批处理，或者其他原因，导致消息消费的速度小于生产的速度。这样会直接导致消息堆积问题，从而影响业务功能。

![消息队列-问题-消息堆积](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-问题-消息堆积.png)

以下单开通会员为例，若消息出现堆积，会导致用户下单后，很久之后才能变成会员，这种情况肯定会引起大量用户投诉。



### 系统复杂度提升

这里说的系统复杂度和系统耦合性是不一样的，比如以前只有：系统A、系统B和系统C 这三个系统，现在引入MQ之后，你除了需要关注前面三个系统之外，还需要关注MQ服务，需要关注的点越多，系统的复杂度越高。

![消息队列-问题-系统复杂度提升](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-问题-系统复杂度提升.png)

MQ的机制需要：生产者、MQ服务器、消费者。有一定的学习成本，需要额外部署MQ服务器，而且有些MQ比如：RocketMQ，功能非常强大，用法有点复杂，如果使用不好，会出现很多问题。有些问题，不像接口调用那么容易排查，从而导致系统的复杂度提升了。



## 解决引发问题

MQ是一种趋势，总体来说对我们的系统是利大于弊的，那么要如何解决这些问题呢？

### 重复消息问题

不管是由于生产者产生的重复消息，还是由于消费者导致的重复消息，我们都可以在消费者中这个问题。这就要求消费者在做业务处理时，要做幂等设计。在这里推荐增加一张消费消息表，来解决MQ的这类问题。消费消息表中，使用`messageId`做`唯一索引`，在处理业务逻辑之前，先根据messageId查询一下该消息有没有处理过，如果已经处理过了则直接返回成功，如果没有处理过，则继续做业务处理。解决方案：

- **在消费放使用messageId做唯一索引进行幂等处理**
- **在消费方根据业务唯一标识（如订单号、流水号）进行幂等处理 —— 推荐**

![消息队列-解决-重复消息问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-重复消息问题.png)



### 数据一致性问题

数据一致性分为强一致性、弱一致性和最终一致性。而MQ为了性能考虑使用的是`最终一致性`，那么必定会出现数据不一致的问题。这类问题大概率是因为消费者读取消息后，业务逻辑处理失败导致的，这时候可以增加`重试机制`。重试分为：`同步重试` 和 `异步重试`。业务处理失败后，可以采用以下三种方式进行重试：

- **同步重试**
  - 立即重试3-5次，若还是失败，则写入`记录表`，人工处理。推荐`消息量小`的场景使用
- **异步重试**
  - 立刻写入`重试表`，使用Job定时重试。推荐在`消息量大`的场景使用
  - 消费失败后，将消息再发至消息队列的同一个Topic中。推荐在`顺序要求不高`的场景

![消息队列-解决-数据一致性问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-数据一致性问题.png)

有些消息量比较小的业务场景，可以采用同步重试，在消费消息时如果处理失败，立刻重试3-5次，如何还是失败，则写入到`记录表`中。但如果消息量比较大，则不建议使用这种方式，因为如果出现网络异常，可能会导致大量的消息不断重试，影响消息读取速度，造成`消息堆积`。而消息量比较大的业务场景，建议采用异步重试，在消费者处理失败之后，立刻写入`重试表`，有个`job`专门定时重试。还有一种做法是，如果消费失败，自己给同一个Topic发一条消息，在后面的某个时间点，自己又会消费到那条消息，起到了重试的效果。如果对消息顺序要求不高的场景，可以使用这种方式。



### 消息丢失问题

不管你是否承认有时候消息真的会丢，即使这种概率非常小，也会对业务有影响。生产者、MQ服务器、消费者都有可能会导致消息丢失的问题。

为了解决这个问题，可以增加一张`消息发送表`，当生产者发完消息之后，会往该表中写入一条数据，状态status标记为待确认。如果消费者读取消息之后，调用生产者的api更新该消息的status为已确认。有个Job，每隔一段时间检查一次消息发送表，如果5分钟（这个时间可以根据实际情况来定）后还有状态是待确认的消息，则认为该消息已经丢失了，重新发条消息。

![消息队列-解决-消息丢失问题](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息丢失问题.png)

这样不管是由于生产者、MQ服务器、还是消费者导致的消息丢失问题，job都会重新发消息。



### 消息顺序问题

消息顺序问题是非常常见的问题，以`Kafka`消费订单消息为例。订单有：下单、支付、完成、退货等状态，这些状态是有先后顺序的，如果顺序错了会导致业务异常。解决这类问题之前，我们先确认一下，消费者是否真的需要知道中间状态，只知道最终状态行不行？

![消息队列-解决-消息顺序问题1](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息顺序问题1.png)

其实很多时候，只需要知道的是最终状态，这时可以把流程优化一下：

![消息队列-解决-消息顺序问题2](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息顺序问题2.png)

这种方式可以解决大部分的消息顺序问题。但如果真的有需要保证消息顺序的需求。订单号路由到不同的`partition`，同一个订单号的消息，每次到发到同一个`partition`。

![消息队列-解决-消息顺序问题3](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息顺序问题3.png)



### 消息堆积问题

如果消费者消费消息的速度小于生产者生产消息的速度，将会出现消息堆积问题。那么消息堆积问题该如何解决呢？这个要看消息是否需要保证顺序。如果不需要保证顺序，可以读取消息之后用多线程处理业务逻辑。

![消息队列-解决-消息堆积1](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息堆积1.png)

这样就能增加业务逻辑处理速度，解决消息堆积问题。但线程池的核心线程数和最大线程数需要合理配置，不然可能会浪费系统资源。如果需要保证顺序，可以读取消息之后，将消息按照一定规则分发到多个队列中，然后在队列中用单线程处理。

![消息队列-解决-消息堆积2](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/消息队列-解决-消息堆积2.png)

## 使用场景

其实MQ相关的内容还有很多，比如：延迟消息、私信队列、事务问题等等。



### 延迟队列

延迟队列存储的对象肯定是对应的延时消息，所谓”延时消息”是指当消息被发送以后，并不想让消费者立即拿到消息，而是等待指定时间后，消费者才拿到这个消息进行消费。开源RocketMQ 不支持任意时间自定义的延迟消息，仅支持内置预设值的延迟时间间隔的延迟消息。预设值的延迟时间间隔为：1s、 5s、 10s、 30s、 1m、 2m、 3m、 4m、 5m、 6m、 7m、 8m、 9m、 10m、 20m、 30m、 1h、 2h。

如电商中，提交一个订单就可以发送一个延时消息，30m后去检查这个订单的状态，如果还未付款就取消订单释放库存。

```java
 Message msg = new Message("order", "订单001".getBytes());
// 延迟30分钟
msg.setDelayTimeLevel(16);
SendResult sendResult = producer.send(msg);
```



### 死信队列

当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。

**死信消息**

- 不会再被消费者正常消费
- 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理

**死信队列**

- 一个死信队列对应一个 Group ID， 而不是对应单个消费者实例
- 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列
- 一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic



死信队列中的数据需要通过新订阅该topic进行消费。每个topic被消费后，如果消费失败超过次数会进入重试队列、死信队列等。名称会以：

- **%RETRY%消费组名称**
- **%DLQ%消费组名称**



订单失效问题比较麻烦的地方就是如何能够实时获取失效的订单。对于这种问题一般有两种解决方案： 

- **定时任务处理**
  用户下订单后先生成订单信息，然后将该订单加入到定时任务中（30分钟后执行），当到达指定时间后检查订单状态，如果未支付则标识该订单失效。定时去轮询数据库/缓存，看订单的状态。这种方式的问题很明显，当集群部署服务器的时候需要做分布式锁进行协调，而且实时性不高，对数据库会产生压力。

  ![Job扫描处理超时未支付订单](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/Job扫描处理超时未支付订单.png)

- **延时任务处理**
  当用户下订单后，将用户的订单的标识全部发送到延时队列中，30分钟后进去消费队列中被消费，消费时先检查该订单的状态，如果未支付则标识该订单失效。有以下几种延时任务处理方式：

  - **Java自带的DelayedQuene队列**
    这是java本身提供的一种延时队列，如果项目业务复杂性不高可以考虑这种方式。它是使用jvm内存来实现的，停机会丢失数据，扩展性不强。

  - **使用redis监听key的过期来实现**
    当用户下订单后把订单信息设置为redis的key，30分钟失效，程序编写监听redis的key失效，然后处理订单（我也尝试过这种方式）。这种方式最大的弊端就是只能监听一台redis的key失效，集群下将无法实现，也有人监听集群下的每个redis节点的key，但我认为这样做很不合适。如果项目业务复杂性不高，redis单机部署，就可以考虑这种方式。

  - **MQ死信队列实现**

    ![死信队列处理超时未支付订单](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/死信队列处理超时未支付订单.png)



### 事务问题

![RocketMQ事务消息](C:/Users/DELL/Downloads/lemon-guide-main/images/Solution/RocketMQ事务消息.png)

